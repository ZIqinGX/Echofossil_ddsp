import os
import numpy as np
import librosa
import gin
from scipy.io.wavfile import write as write_wav

from ddsp.training.preprocessing import F0LoudnessPreprocessor
from ddsp.training.models import Autoencoder
from ddsp.spectral_ops import compute_f0, compute_loudness

# === ç”¨æˆ·è·¯å¾„ï¼ˆè¯·æŒ‰éœ€ä¿®æ”¹ï¼‰ ===
GIN_FILE   = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\models\violin\operative_config-0.gin'
CKPT_FILE  = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\models\violin\ckpt-40000'
INPUT_WAV  = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\audio\input.wav'
OUTPUT_WAV = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\output\output.wav'

# === è¶…å‚æ•° ===
TARGET_SR  = 16000  # é‡‡æ ·ç‡
FRAME_RATE = 250    # ç‰¹å¾å¸§ç‡

def save_audio(path: str, audio: np.ndarray, sr: int):
    """ä¿å­˜ä¸º 16-bit PCM WAV"""
    wav_int16 = np.int16(audio / np.max(np.abs(audio)) * 32767)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    write_wav(path, sr, wav_int16)
    print(f"âœ… åˆæˆæ–‡ä»¶ä¿å­˜åˆ°ï¼š{path}")

# 1. è½½å…¥ Gin é…ç½®ï¼ˆåªä¸ºäº†è¯»å– model çš„æ¶æ„ï¼è¶…å‚ï¼‰
gin.parse_config_file(GIN_FILE)

# 2. è¯»å…¥å¹¶é‡é‡‡æ ·éŸ³é¢‘
audio, sr = librosa.load(INPUT_WAV, sr=TARGET_SR, mono=True)
print(f"ğŸ§ å·²åŠ è½½éŸ³é¢‘ï¼š{INPUT_WAV} | SR={sr} | æ—¶é•¿={len(audio)/sr:.2f}s")

# 3. æ‰‹åŠ¨æå–åŸå§‹ç‰¹å¾
f0_hz, f0_conf = compute_f0(audio, FRAME_RATE)
loudness_db    = compute_loudness(audio, FRAME_RATE)

# 4. å¯¹é½å¸§æ•°åˆ°æ¨¡å‹æœŸæœ›
hop_size = TARGET_SR // FRAME_RATE
n_frames = len(audio) // hop_size
f0_hz       = f0_hz[:n_frames]
f0_conf     = f0_conf[:n_frames]
loudness_db = loudness_db[:n_frames]
print(f"ğŸ“ˆ ç‰¹å¾å¸§æ•°å¯¹é½ï¼š{n_frames}")

# 5. åˆå§‹åŒ–é¢„å¤„ç†å™¨ï¼Œåªåšâ€œåŸå§‹â†’scaledâ€ï¼Œä¸é‡æ–°è®¡ç®— f0/loudness
prep = F0LoudnessPreprocessor(sample_rate=TARGET_SR, frame_rate=FRAME_RATE)
# å…³é—­å†…éƒ¨é‡ç®—
prep.compute_f0 = False
prep.compute_loudness = False

# å‡†å¤‡æ—  batch çš„åŸå§‹ç‰¹å¾ dict
features_raw = {
    'f0_hz':         f0_hz[np.newaxis, :],
    'f0_confidence': f0_conf[np.newaxis, :],
    'loudness_db':   loudness_db[np.newaxis, :]
}

# å¾—åˆ° scaled ç‰¹å¾ï¼ˆdict åŒ…å« 'f0_scaled' å’Œ 'ld_scaled'ï¼‰
scaled_feats = prep(features_raw, training=False)

# 6. åŠ è½½æ¨¡å‹å¹¶ restore
model = Autoencoder()
model.restore(CKPT_FILE)
print(f"âœ… æ¨¡å‹å·²åŠ è½½ï¼š{CKPT_FILE}")

# 7. ç›´æ¥ decodeï¼ˆä¼ å…¥ scaled_featsï¼‰
audio_tensor = model.decode(scaled_feats, training=False)
audio_out    = audio_tensor.numpy().flatten()

# 8. ä¿å­˜åˆæˆç»“æœ
save_audio(OUTPUT_WAV, audio_out, TARGET_SR)
