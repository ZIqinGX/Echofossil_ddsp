import os
import numpy as np
import librosa
from scipy.io.wavfile import write as write_wav

import ddsp
import gin
from ddsp.training.models import Autoencoder
from ddsp.spectral_ops import compute_f0, compute_loudness

# === è·¯å¾„è®¾ç½® ===
GIN_FILE   = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\models\violin\operative_config-0.gin'
CKPT_FILE = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\models\violin\ckpt-40000'
INPUT_WAV  = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\audio\input.wav'
OUTPUT_WAV = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\output\output.wav'

# === è¶…å‚ ===
TARGET_SR  = 16000
FRAME_RATE = 250

def save_audio(path, audio, sr):
    audio_int16 = np.int16(audio / np.max(np.abs(audio)) * 32767)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    write_wav(path, sr, audio_int16)
    print(f"âœ… ä¿å­˜ï¼š{path}")

# 1. è¯»å¹¶é‡é‡‡æ ·
audio, sr = librosa.load(INPUT_WAV, sr=TARGET_SR, mono=True)
print(f"ğŸ§ åŠ è½½éŸ³é¢‘: {INPUT_WAV} é‡‡æ ·ç‡={sr} æ—¶é•¿={len(audio)/sr:.2f}s")

# 2. ç‰¹å¾æå–ï¼ˆæ‰‹åŠ¨åšé¢„å¤„ç†ï¼‰
f0_hz, f0_conf   = compute_f0(audio, FRAME_RATE)
loudness_db      = compute_loudness(audio, FRAME_RATE)
n = min(len(f0_hz), len(loudness_db))
f0_hz, f0_conf  = f0_hz[:n], f0_conf[:n]
loudness_db     = loudness_db[:n]
features = {
    'f0_hz': f0_hz[np.newaxis, :],
    'f0_confidence': f0_conf[np.newaxis, :],
    'loudness_db': loudness_db[np.newaxis, :]
}
print(f"ğŸ“ˆ ç‰¹å¾å¸§æ•°: {n}")

# 3. åŠ è½½æ¨¡å‹
gin.parse_config_file(GIN_FILE)
model = Autoencoder()
model.restore(CKPT_FILE)
print(f"âœ… æ¨¡å‹åŠ è½½: {CKPT_FILE}")

# 4. æ¨ç†åˆæˆ
# æŠŠ audio å’Œ ç‰¹å¾ åˆå¹¶åˆ°åŒä¸€ä¸ªè¾“å…¥ dict
# 4. æ¨ç†åˆæˆ
model_input = {
    'audio': audio[np.newaxis, :],
    'f0_hz': f0_hz[np.newaxis, :],
    'f0_confidence': f0_conf[np.newaxis, :],
    'loudness_db': loudness_db[np.newaxis, :]
}
outputs = model(model_input, training=False)

# å…¼å®¹å• Tensor æˆ– dict
if isinstance(outputs, dict):
    audio_tensor = outputs['audio_synth']
else:
    audio_tensor = outputs

audio_out = audio_tensor.numpy().flatten()

# 5. ä¿å­˜
save_audio(OUTPUT_WAV, audio_out, TARGET_SR)