import os
import numpy as np
import librosa
import gin
import scipy.signal
from scipy.signal import iirpeak, lfilter
import numpy as np
from scipy.io.wavfile import write as write_wav

from ddsp.training.preprocessing import F0LoudnessPreprocessor
from ddsp.training.models import Autoencoder
from ddsp.spectral_ops import compute_f0, compute_loudness

# === ç”¨æˆ·è·¯å¾„ï¼ˆè¯·æŒ‰éœ€ä¿®æ”¹ï¼‰ ===
GIN_FILE   = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\models\violin\operative_config-0.gin'
CKPT_FILE  = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\models\violin\ckpt-40000'
INPUT_WAV  = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\audio\input.wav'
OUTPUT_WAV = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\output\output.wav'

# === è¶…å‚æ•° ===
TARGET_SR  = 16000  # é‡‡æ ·ç‡
FRAME_RATE = 250    # ç‰¹å¾å¸§ç‡

def save_audio(path: str, audio: np.ndarray, sr: int):
    """ä¿å­˜ä¸º 16-bit PCM WAV"""
    wav_int16 = np.int16(audio / np.max(np.abs(audio)) * 32767)
    os.makedirs(os.path.dirname(path), exist_ok=True)
    write_wav(path, sr, wav_int16)
    print(f"âœ… åˆæˆæ–‡ä»¶ä¿å­˜åˆ°ï¼š{path}")

# 1. è½½å…¥ Gin é…ç½®ï¼ˆåªä¸ºäº†è¯»å– model çš„æ¶æ„ï¼è¶…å‚ï¼‰
gin.parse_config_file(GIN_FILE)

# 2. è¯»å…¥å¹¶é‡é‡‡æ ·éŸ³é¢‘
audio, sr = librosa.load(INPUT_WAV, sr=TARGET_SR, mono=True)
print(f"ğŸ§ å·²åŠ è½½éŸ³é¢‘ï¼š{INPUT_WAV} | SR={sr} | æ—¶é•¿={len(audio)/sr:.2f}s")

# 3. æ‰‹åŠ¨æå–åŸå§‹ç‰¹å¾
f0_hz_raw, f0_conf = compute_f0(audio, FRAME_RATE)
f0_hz = scipy.signal.medfilt(f0_hz_raw, kernel_size=5)
loudness_db    = compute_loudness(audio, FRAME_RATE)

# 4. å¯¹é½å¸§æ•°åˆ°æ¨¡å‹æœŸæœ›
hop_size = TARGET_SR // FRAME_RATE
n_frames = len(audio) // hop_size
f0_hz       = f0_hz[:n_frames]
f0_conf     = f0_conf[:n_frames]
loudness_db = loudness_db[:n_frames]
print(f"ğŸ“ˆ ç‰¹å¾å¸§æ•°å¯¹é½ï¼š{n_frames}")

# 5. åˆå§‹åŒ–é¢„å¤„ç†å™¨ï¼Œåªåšâ€œåŸå§‹â†’scaledâ€ï¼Œä¸é‡æ–°è®¡ç®— f0/loudness
prep = F0LoudnessPreprocessor(sample_rate=TARGET_SR, frame_rate=FRAME_RATE)
# å…³é—­å†…éƒ¨é‡ç®—
prep.compute_f0 = False
prep.compute_loudness = False

# å‡†å¤‡æ—  batch çš„åŸå§‹ç‰¹å¾ dict
features_raw = {
    'f0_hz':         f0_hz[np.newaxis, :],
    'f0_confidence': f0_conf[np.newaxis, :],
    'loudness_db':   loudness_db[np.newaxis, :]
}

# å¾—åˆ° scaled ç‰¹å¾ï¼ˆdict åŒ…å« 'f0_scaled' å’Œ 'ld_scaled'ï¼‰
scaled_feats = prep(features_raw, training=False)
scaled_feats['ld_scaled'] = scaled_feats['ld_scaled'] * 1.08

# 6. åŠ è½½æ¨¡å‹å¹¶ restore
model = Autoencoder()
model.restore(CKPT_FILE)
print(f"âœ… æ¨¡å‹å·²åŠ è½½ï¼š{CKPT_FILE}")

# 7. ç›´æ¥ decodeï¼ˆä¼ å…¥ scaled_featsï¼‰
audio_tensor = model.decode(scaled_feats, training=False)
audio_out    = audio_tensor.numpy().flatten()


def peaking_eq(audio, sr, center=2500, Q=1.0, gain_db=6):
    """
    åœ¨ä¸­å¿ƒé¢‘ç‡é™„è¿‘åšçª„å¸¦å³°å€¼æå‡ï¼š
    - center: å³°å€¼æ»¤æ³¢ä¸­å¿ƒé¢‘ç‡ï¼ˆHzï¼‰
    - Q: å³°å€¼æ»¤æ³¢å™¨å“è´¨å› æ•°
    - gain_db: æå‡çš„ dB å€¼
    """
    # 1) è®¾è®¡ unit-gain å³°å€¼æ»¤æ³¢å™¨
    w0 = center / (sr / 2)   # å½’ä¸€åŒ–åˆ° [0,1]
    b, a = iirpeak(w0, Q)
    # 2) æŠŠ bï¼ˆæ»¤æ³¢å™¨åˆ†å­ï¼‰ä¹˜ä¸Šçº¿æ€§å¢ç›Š
    gain_lin = 10**(gain_db / 20)
    b = b * gain_lin
    # 3) åº”ç”¨ IIR æ»¤æ³¢
    return lfilter(b, a, audio)


# 8. ä¿å­˜åˆæˆç»“æœ
# ä¿å­˜ boosted ç‰ˆæœ¬
audio_eq = peaking_eq(audio_out, TARGET_SR,
                      center=2500, Q=1.2, gain_db=5)
save_audio(OUTPUT_WAV.replace('.wav','_eq2.wav'),
           audio_eq, TARGET_SR)


