import os
import sys
import numpy as np
import librosa
from scipy.io.wavfile import write as write_wav

import gin
import ddsp
import ddsp.training
from ddsp.training.models import Autoencoder
from ddsp.spectral_ops import compute_f0, compute_loudness

def save_audio(path, audio, sample_rate):
    """æŠŠæµ®ç‚¹[-1,1]çš„éŸ³é¢‘ä¿å­˜æˆ 16-bit WAV."""
    # é˜²æ­¢æº¢å‡º
    audio = np.clip(audio, -1.0, 1.0)
    # è½¬ int16
    audio_int16 = (audio * 32767).astype(np.int16)
    write_wav(path, sample_rate, audio_int16)

# === è·¯å¾„è®¾ç½® ===
GIN_FILE   = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\models\flute\operative_config-0.gin'
CKPT_FILE  = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\models\flute\ckpt-20000'
INPUT_WAV  = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\audio\input2.wav'
OUTPUT_WAV = r'C:\Users\OS\Desktop\MusicRecordingTransfeer\ddsp_test\output_flute\output2.wav'

# === è¶…å‚ ===
TARGET_SR  = 16000
FRAME_RATE = 250

# è§£æé…ç½®æ—¶è·³è¿‡é‚£äº›ä¸å­˜åœ¨çš„ç»‘å®šï¼ˆSoloFluteã€train.* ç­‰ï¼‰
gin.parse_config_file(GIN_FILE, skip_unknown=True)

# 1. è¯»å¹¶é‡é‡‡æ ·
audio, sr = librosa.load(INPUT_WAV, sr=TARGET_SR, mono=True)
print(f"ğŸ§ åŠ è½½éŸ³é¢‘: {INPUT_WAV} é‡‡æ ·ç‡={sr} æ—¶é•¿={len(audio)/sr:.2f}s")

# 2. ç‰¹å¾æå–ï¼ˆæ‰‹åŠ¨åšé¢„å¤„ç†ï¼‰
f0_hz, f0_conf   = compute_f0(audio, FRAME_RATE)
loudness_db      = compute_loudness(audio, FRAME_RATE)
n = min(len(f0_hz), len(loudness_db))
f0_hz, f0_conf  = f0_hz[:n], f0_conf[:n]
loudness_db     = loudness_db[:n]
features = {
    'f0_hz': f0_hz[np.newaxis, :],
    'f0_confidence': f0_conf[np.newaxis, :],
    'loudness_db': loudness_db[np.newaxis, :]
}
print(f"ğŸ“ˆ ç‰¹å¾å¸§æ•°: {n}")

# 3. åŠ è½½æ¨¡å‹
gin.parse_config_file(GIN_FILE)
model = Autoencoder()
model.restore(CKPT_FILE)
print(f"âœ… æ¨¡å‹åŠ è½½: {CKPT_FILE}")

# 4. æ¨ç†åˆæˆ
# æŠŠ audio å’Œ ç‰¹å¾ åˆå¹¶åˆ°åŒä¸€ä¸ªè¾“å…¥ dict
# 4. æ¨ç†åˆæˆ
model_input = {
    'audio': audio[np.newaxis, :],
    'f0_hz': f0_hz[np.newaxis, :],
    'f0_confidence': f0_conf[np.newaxis, :],
    'loudness_db': loudness_db[np.newaxis, :]
}
outputs = model(model_input, training=False)

# å…¼å®¹å• Tensor æˆ– dict
if isinstance(outputs, dict):
    audio_tensor = outputs['audio_synth']
else:
    audio_tensor = outputs

audio_out = audio_tensor.numpy().flatten()

# 5. ä¿å­˜
save_audio(OUTPUT_WAV, audio_out, TARGET_SR)